{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will be looking at how multi-model search can be done in AquilaDB. We will build a tool similar to Google Image search and we will be performing direct (text to image) and reverse (image to image) search with the help of two pretrained models - one is for text and the other one for image.\n",
    "\n",
    "To make things faster and easier, will be using a `Fasttext` model for sentance embedding and a `MobileNet` model for image encoding.\n",
    "\n",
    "This tutorial will be fast and will skim some unwanted details in code. If you find it hard to follow, please refer previous tutorials where we take more time to discuss those details in the code.\n",
    "\n",
    "So, Let's begin.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Install and import all required python librarries (we will be installing & importing AquilaDb library later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /home/iamjbn/miniconda3/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from fasttext) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from fasttext) (41.0.0)\n",
      "Requirement already satisfied: numpy in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from fasttext) (1.16.2)\n",
      "Requirement already satisfied: Pillow in /home/iamjbn/miniconda3/lib/python3.7/site-packages (6.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/iamjbn/miniconda3/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: six in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.0)\n",
      "Requirement already satisfied: tensorflow_hub==0.4.0 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from tensorflow_hub==0.4.0) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from tensorflow_hub==0.4.0) (1.16.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from tensorflow_hub==0.4.0) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from protobuf>=3.4.0->tensorflow_hub==0.4.0) (41.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "!pip install Pillow\n",
    "!pip install matplotlib\n",
    "!pip install \"tensorflow_hub==0.4.0\"\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import pandas as pd\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Flicker30k images dataset\n",
    "\n",
    "You need to download [Flickr Image captioning dataset](https://www.kaggle.com/hsankesara/flickr-image-dataset) and extract it to a convinient location. We have extracted it into a directory `./flickr30k_images/` which is in the same directory as this notebook.\n",
    "\n",
    "Load results.csv file as a Pandas dataframe - which contains all the captions along with file names of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image descriptions\n",
    "image_descriptions = pd.read_csv('./flickr30k_images/results.csv', sep='\\|\\s', engine='python')\n",
    "selected_columns = ['image_name', 'comment']\n",
    "image_descriptions = image_descriptions[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and load Fasttext Model\n",
    "\n",
    "Now let's quickly build a Fasttext language model from the raw comments that we have. \n",
    "\n",
    "To make things easy, we already have extracted all the comments from the CSV file to a text file - `results.txt`.\n",
    "Let's train the Fasttext model on our data in skipgram unsupervised mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a language model quickly with fasttext\n",
    "fasttext_model = ft.train_unsupervised(model='skipgram', input='flickr30k_images/results.txt')\n",
    "# save model\n",
    "fasttext_model.save_model(\"ftxt_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load saved model\n",
    "fasttext_model = ft.load_model(\"ftxt_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the model encodes the semantic information for different words properly. \n",
    "\n",
    "Note that, fasttext is not good for encoding semantic information for sentances. We are using it here, because we expect the user to search images by giving importance to the words - resulting each object in the image rather than the overall context of the image. \n",
    "\n",
    "In case you wanted semantic sentance based retrieval, feel free to use better language models (slower than Fasttext) like Universal Sentance Encoder. We have a tutorial on that [over here](https://github.com/a-mma/AquilaDB/wiki/Semantic-Text-Retrieval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing word vectors... done.\n",
      "Query word? little 0.81607\n",
      "child 0.749877\n",
      "Girl 0.730085\n",
      "pink 0.729028\n",
      "Little 0.728659\n",
      "boy 0.721146\n",
      "young 0.70541\n",
      "Child 0.696403\n",
      "blond 0.69241\n",
      "pigtails 0.683836\n",
      "Query word? ===============\n",
      "Pre-computing word vectors... done.\n",
      "Query word? gardening 0.851279\n",
      "Garden 0.75108\n",
      "greenhouse 0.670199\n",
      "yard 0.644325\n",
      "farmland 0.621978\n",
      "graveyard 0.610896\n",
      "planting 0.606963\n",
      "plant 0.606599\n",
      "soil 0.600708\n",
      "dandelions 0.598445\n",
      "Query word? ===============\n",
      "Pre-computing word vectors... done.\n",
      "Query word? glassware 0.758021\n",
      "wineglass 0.697829\n",
      "liquor 0.666033\n",
      "liquid 0.663535\n",
      "windowsill 0.630589\n",
      "glasses 0.627794\n",
      "mug 0.619218\n",
      "cocktail 0.618122\n",
      "pours 0.613753\n",
      "windows 0.610867\n",
      "Query word? ===============\n",
      "Pre-computing word vectors... done.\n",
      "Query word? t-ball 0.850855\n",
      "T-ball 0.842449\n",
      "ballgame 0.822507\n",
      "A&M 0.745541\n",
      "Tennis 0.731484\n",
      "Rugby 0.726965\n",
      "rugby 0.719968\n",
      "33 0.719124\n",
      "defends 0.716951\n",
      "racquet 0.71034\n",
      "Query word? "
     ]
    }
   ],
   "source": [
    "# test the language model\n",
    "! echo \"girl\" | fasttext nn ftxt_model.bin\n",
    "! echo \"===============\" \n",
    "! echo \"garden\" | fasttext nn ftxt_model.bin\n",
    "! echo \"===============\" \n",
    "! echo \"glass\" | fasttext nn ftxt_model.bin\n",
    "! echo \"===============\" \n",
    "! echo \"ball\" | fasttext nn ftxt_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case you wonder how we generate sentance embedding from Fasttext, here's a one-liner to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.55252177e-02,  4.62995056e-04, -5.44314571e-02, -3.67470682e-02,\n",
       "        5.60869165e-02, -8.12834278e-02,  3.80968209e-03, -2.74911691e-02,\n",
       "        9.01712254e-02,  9.78767499e-02, -6.08064700e-03,  5.08974819e-03,\n",
       "        7.14183077e-02,  4.63549010e-02, -4.58772071e-02,  5.99741424e-03,\n",
       "        1.61642864e-01,  4.43923697e-02,  5.18643633e-02, -3.34854349e-02,\n",
       "        4.54470590e-02,  7.50896782e-02,  1.40062913e-01, -2.87059303e-02,\n",
       "        1.37019539e-02, -9.83393714e-02,  8.02637078e-03, -1.11153862e-02,\n",
       "       -4.84096855e-02, -4.27665487e-02, -3.36519293e-02,  6.60182387e-02,\n",
       "        6.28363248e-03,  7.19422996e-02, -1.33004934e-01,  5.96968718e-02,\n",
       "        2.60726940e-02, -2.05314308e-02, -1.19173704e-02,  1.07480362e-01,\n",
       "       -6.55921623e-02,  3.79568562e-02, -4.68304418e-02,  4.59685735e-02,\n",
       "        1.71747860e-02,  1.02798633e-01, -1.39811680e-01,  1.52558496e-03,\n",
       "       -5.71033135e-02,  7.27988854e-02,  2.66344007e-02, -1.88209787e-02,\n",
       "       -6.96759000e-02,  4.93013486e-02,  1.17437121e-04,  1.25494108e-01,\n",
       "        1.40687805e-02, -1.73967794e-01,  1.22020334e-01,  1.08640499e-01,\n",
       "       -4.75100195e-03,  2.42577419e-02,  2.20628325e-02,  5.55606671e-02,\n",
       "        1.33873681e-02,  2.91601457e-02, -3.18597257e-02, -9.90993455e-02,\n",
       "       -4.83357385e-02, -3.62710021e-02,  8.17621686e-03, -6.41942099e-02,\n",
       "       -2.01496370e-02, -9.04923379e-02,  6.00407505e-03, -9.46219787e-02,\n",
       "       -2.21200306e-02,  2.17031203e-02,  9.03992206e-02, -3.22397165e-02,\n",
       "        5.17626517e-02, -4.68562916e-02,  7.82131329e-02, -1.10009618e-01,\n",
       "       -5.38079883e-04,  7.79205188e-03,  5.83799072e-02,  1.47165224e-01,\n",
       "        2.75171385e-03,  1.22609712e-01,  2.81057674e-02, -5.59783280e-02,\n",
       "        5.96124977e-02, -1.29236341e-01,  5.84035628e-02,  1.21095881e-01,\n",
       "        5.16762286e-02,  1.02854759e-01, -1.47027825e-03, -1.08863831e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert string to embeddings\n",
    "fasttext_model.get_sentence_vector('a cat is sitting on the carpet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanup data (dataframe)\n",
    "\n",
    "Before we proceed into the core of this tutorial, we need to cleanup the dataframe to keep only what we wanted. The code below is self explanatory, if you have a background knowledge using Pandas. We are skipping the explanation just because it is out of scope of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young guys with shaggy hair look at their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>Several men in hard hats are operating a giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000344755.jpg</td>\n",
       "      <td>Someone in a blue shirt and hat is standing on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name                                            comment\n",
       "0   1000092795.jpg  Two young guys with shaggy hair look at their ...\n",
       "5     10002456.jpg  Several men in hard hats are operating a giant...\n",
       "10  1000268201.jpg  A child in a pink dress is climbing up a set o...\n",
       "15  1000344755.jpg  Someone in a blue shirt and hat is standing on..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concater(x):\n",
    "    try:\n",
    "        return ' '.join(x)\n",
    "    except Exception as e:\n",
    "        return ''\n",
    "\n",
    "# concatenate strings for same images\n",
    "image_descriptions['comment'] = image_descriptions.groupby(['image_name'])['comment'].transform(concater)\n",
    "image_descriptions = image_descriptions[['image_name','comment']].drop_duplicates()\n",
    "image_descriptions.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000092795.jpg Two young guys with shaggy hair look at their hands while hanging out in the yard . Two young , White males are outside near many bushes . Two men in green shirts are standing in a yard . A man in a blue shirt standing in a garden . Two friends enjoy time spent together .\n",
      "10002456.jpg Several men in hard hats are operating a giant pulley system . Workers look down from up above on a piece of equipment . Two men working on a machine wearing hard hats . Four men on top of a tall structure . Three men on a large rig .\n",
      "1159425410.jpg A female washes her medium-sized dog outdoors in a plastic container while a friend secures it with a leash . A brown dog is in a blue tub , while one person holds his leash and another is soaping him . Two people give a dog a bath outdoors in a blue container . A small brown dog is being washed in a small blue bin . A dog calmly waits until his bath is over .\n"
     ]
    }
   ],
   "source": [
    "# verify comments in each row\n",
    "print(image_descriptions.iloc[0][0], image_descriptions.iloc[0][1])\n",
    "print(image_descriptions.iloc[1][0], image_descriptions.iloc[1][1])\n",
    "print(image_descriptions.iloc[500][0], image_descriptions.iloc[500][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained MobileNet Model\n",
    "\n",
    "Now we need to load pretrained MobileNet model from Tensorflow Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 14:57:32.937887 139627470767936 deprecation.py:506] From /home/iamjbn/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# load mobilenet featurevector model as a Keras layer\n",
    "module = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n",
    "        output_shape=[1280],\n",
    "        trainable=False)\n",
    "])\n",
    "\n",
    "# build the model\n",
    "module.build([None, 224, 224, 3])\n",
    "\n",
    "# This model will only accept images of size 224 x 224\n",
    "# So, we need to make sure throughout the code, that we supply correcty resized images\n",
    "im_height, im_width = 224, 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Here are some self explanatory helper functions that will help us during the embed/encode/predict stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the helper function to load and resize image\n",
    "def load_rsize_image(filename, w, h):\n",
    "    # open the image file\n",
    "    im = Image.open(filename)\n",
    "    # resize the image\n",
    "    im = im.resize(size=(w, h))\n",
    "    return np.asarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd17fc6518>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's test loading an image\n",
    "image_array = load_rsize_image('./flickr30k_images/flickr30k_images/301246.jpg', im_width, im_height)\n",
    "plt.imshow(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to retrieve fasttext word embeddings\n",
    "def get_ftxt_embeddings(text):\n",
    "    return fasttext_model.get_sentence_vector(text)\n",
    "\n",
    "# helper function to encode images with mobilenet\n",
    "def get_image_encodings(batch, module):\n",
    "    message_embeddings = module.predict(batch)\n",
    "    return message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to embed images and comments in a dataframe and return numpy metrices\n",
    "# this function will iterate through a dataframe, which contains image file names in one column and \n",
    "# comments in another column and will generate seperate matrices for images and comments.\n",
    "# row order of these matrices matters because same row index in both matrices represent related image and comments.\n",
    "def embed_all(df, w, h):\n",
    "    img_arr = []\n",
    "    txt_arr = []\n",
    "    # for each row, embed data\n",
    "    for index, row in df.iterrows():\n",
    "        # img_arr will contain all the image file data (will be passed to mobilenet later)\n",
    "        img_arr.append(load_rsize_image('./flickr30k_images/flickr30k_images/' + row['image_name'], w, h))\n",
    "        # txt_arr will contain all Fasttext sentance embedding for each comment \n",
    "        txt_arr.append(get_ftxt_embeddings(row['comment']))\n",
    "    return img_arr, txt_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_emb, txt_emb = embed_all(image_descriptions, im_width, im_height)\n",
    "# reset fasttext model\n",
    "fasttext_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa6041ef2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verify that image is image loded correctly\n",
    "plt.imshow(img_emb[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ablove steps, we have embedded text data with Fasttext. Image data still need to be encoded. To keep the CPU and RAM away from exploding, we decided to do it in batches, before sending them to AquilaDB.\n",
    "\n",
    "But just in case you wonder how an image can be encoded, here is a one-liner for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1280)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test image encodings generation\n",
    "get_image_encodings(np.true_divide(np.array(img_emb[0:100]), 255), module).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter based indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the core idea we wanted to share with you through this tutorial.\n",
    "In this tutorial, we are using multiple models that generate encodings. So we need to index both of them inside AquilaDB and need to somehow discriminate (filter) them during k-NN search. With AquilaDB we could do this efficiently.\n",
    "\n",
    "Padding can be done in two ways:\n",
    "1. Positional padding\n",
    "2. Filter vector padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional Padding\n",
    "\n",
    "This is what we will be doing in this tutorial.\n",
    "If you have a limited number of models ranging between 2 to 4, this will be the best method that you can use.\n",
    "\n",
    "Suppose, we have two models `M1` and `M2`. And these models generate vectors `v1` and `v2`.\n",
    "Then we will build two long vectors `vlong` as, `size(vlong) = size(v1) + size(v2)` for each models.\n",
    "\n",
    "Then we will pad each of them with either preceding or following zeroes.\n",
    "\n",
    "Example:\n",
    "\n",
    "v1 = [1, 2, 3, 4, 5]\n",
    "\n",
    "v2 = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "then; size(vlong) = 5 + 10 = 15\n",
    "\n",
    "So, we will be sending two vectors to AquilaDB, each of them are:\n",
    "\n",
    "v1long = [1, 2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "v2long = [0, 0, 0, 0, 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter vector padding\n",
    "\n",
    "If you have more than 4 models, we highly recommend you to use a better Machine Learning model that combine all of these and then use `Positional Padding`. But, ofcause there might be requirements apart from that, then use this method.\n",
    "\n",
    "Cosider designing filter vectors for each model. For example, we have two models M1 and M2. And these models generate vectors v1 and v2. Then, design two filter vectors f1 and f2 as, \n",
    "\n",
    "f1 = [0, 0, 0, 0, 0, 0, ........ n items]\n",
    "\n",
    "f1 = [1, 1, 1, 1, 1, 1, ........ n items]\n",
    "\n",
    "value of `n` is a variable should be chosen to maximize the distance between two filters.\n",
    "\n",
    "So, we will be sending two vectors to AquilaDB, each of them are:\n",
    "\n",
    "v1long = append(f1, v1)\n",
    "\n",
    "v2long = append(f2, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send data to AquilaDB for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aquiladb in /home/iamjbn/miniconda3/lib/python3.7/site-packages (0.5.1)\n",
      "Requirement already satisfied: protobuf in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from aquiladb) (3.8.0)\n",
      "Requirement already satisfied: grpcio in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from aquiladb) (1.20.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from protobuf->aquiladb) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/iamjbn/miniconda3/lib/python3.7/site-packages (from protobuf->aquiladb) (41.0.0)\n"
     ]
    }
   ],
   "source": [
    "# install AquilaDb python client\n",
    "\n",
    "! pip install aquiladb\n",
    "\n",
    "# import AquilaDB client\n",
    "from aquiladb import AquilaClient as acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DB instance.\n",
    "# Please provide the IP address of the machine that have AquilaDB installed in.\n",
    "db = acl('192.168.1.102', 50051)\n",
    "\n",
    "# let's get our hands dirty for a moment..\n",
    "# convert a sample dirty Document\n",
    "sample = db.convertDocument([0.1,0.2,0.3,0.4], {\"hello\": \"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vector': {'e': [0.1, 0.2, 0.3, 0.4]}, 'b64data': b'{\"hello\":\"world\"}'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and print it\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, this is what happens when a document along with a vector is serialized. This will then be sent to AquilaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add documents to AquilaDB\n",
    "\n",
    "In the code below we do a lot of things. So, please pay attention to the comments to see how it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  0 500\n",
      "Done:  500 1000\n",
      "Done:  1000 1500\n",
      "Done:  1500 2000\n",
      "Done:  2000 2500\n",
      "Done:  2500 3000\n",
      "Done:  3000 3500\n",
      "Done:  3500 4000\n",
      "Done:  4000 4500\n",
      "Done:  4500 5000\n",
      "Done:  5000 5500\n",
      "Done:  5500 6000\n"
     ]
    }
   ],
   "source": [
    "# We are going to encode a small portion (6000) images/text that we have downloaded.\n",
    "# You can add more if you have got enough interest, patience and a good machine.\n",
    "\n",
    "# batch length - to be sent to mobilenet for encoding\n",
    "blen = 500\n",
    "# which index to start encoding - ofcause its 0\n",
    "vstart = 0\n",
    "# How much images/text we need to encode\n",
    "vend = 6000\n",
    "\n",
    "# convert text embeddings to numpy array\n",
    "txt_emb = np.array(txt_emb)\n",
    "\n",
    "# iterate over each batch of image/text data/embedding\n",
    "for ndx in range(vstart, vend, blen):\n",
    "    # encode each batch of images\n",
    "    image_encoding = get_image_encodings(np.true_divide(np.array(img_emb[ndx:ndx+blen]), 255), module)\n",
    "    \n",
    "    # pad image and text vectors - this is discussed in section `filter based indexing`\n",
    "    # select subset of data we're interested for text embeddings\n",
    "    text_embedding = txt_emb[ndx:ndx+blen]\n",
    "    # pad text encodings with trailing zeros\n",
    "    text_embedding = np.pad(text_embedding, ((0, 0), (0, 1280)), 'constant')\n",
    "    # pad image encodings with preceding zeros\n",
    "    image_encoding = np.pad(image_encoding, ((0, 0), (100, 0)), 'constant')\n",
    "    \n",
    "    # finally, create and send each document\n",
    "    for i in range(blen):\n",
    "        # create document - text\n",
    "        doc_txt = db.convertDocument(text_embedding[i], {\"image_name\": image_descriptions.iloc[ndx+i][0]})\n",
    "        # create document - image\n",
    "        doc_img = db.convertDocument(image_encoding[i], {\"image_name\": image_descriptions.iloc[ndx+i][0]})\n",
    "        \n",
    "        # send documents - text\n",
    "        db.addDocuments([doc_txt])\n",
    "        # send documents - image\n",
    "        db.addDocuments([doc_img])\n",
    "    \n",
    "    # Wooh! done with nth batch   \n",
    "    print('Done: ', ndx, ndx+blen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show off final results\n",
    "\n",
    "Yeah, we have indexed all our images and texts in AquilaDB. Now it's time ro retrieve them either by text search or by image search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search images by text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# search by text\n",
    "def search_by_text(text_in):\n",
    "    # load saved model\n",
    "    fasttext_model = ft.load_model(\"ftxt_model.bin\")\n",
    "    # generate embeddings\n",
    "    text_embedding_ = fasttext_model.get_sentence_vector(text_in)\n",
    "    # pad text embedding\n",
    "    text_embedding_ = np.pad([text_embedding_], ((0, 0), (0, 1280)), 'constant')\n",
    "\n",
    "    # convert query matrix\n",
    "    q_matrix = db.convertMatrix(np.asarray(text_embedding_[0]))\n",
    "    # do k-NN search\n",
    "    k = 10\n",
    "    result = db.getNearest(q_matrix, k)\n",
    "    return json.loads(result.documents)\n",
    "\n",
    "# render images\n",
    "def render_images(doclist):\n",
    "    for doc in doclist:\n",
    "        filename = doc[\"doc\"][\"image_name\"]\n",
    "        im = Image.open('./flickr30k_images/flickr30k_images/' + filename)\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to image search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_images(search_by_text('people sitting on bench'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to image search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_images(search_by_text('kids playing in garden'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to image search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_images(search_by_text('man riding a bike'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search images by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search by image\n",
    "def search_by_image(image_in, w, h, module):\n",
    "    # load image\n",
    "    q_image = load_rsize_image('./flickr30k_images/flickr30k_images/' + image_in, w, h)\n",
    "    q_image = np.array([np.asarray(q_image)])\n",
    "    # generate encodings\n",
    "    image_encoding_ = get_image_encodings(np.true_divide(q_image, 255), module)\n",
    "    # pad image encodings\n",
    "    image_encoding_ = np.pad(image_encoding_, ((0, 0), (100, 0)), 'constant')\n",
    "\n",
    "    # convert query matrix\n",
    "    q_matrix = db.convertMatrix(np.asarray(image_encoding_[0]))\n",
    "    # do k-NN search\n",
    "    k = 10\n",
    "    result = db.getNearest(q_matrix, k)\n",
    "    return json.loads(result.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image to image search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_im_file = '134206.jpg'\n",
    "\n",
    "# show query image\n",
    "render_images([{\"doc\":{\"image_name\": q_im_file}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do search\n",
    "render_images(search_by_image(q_im_file, im_width, im_height, module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image to image search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_im_file = '11808546.jpg'\n",
    "\n",
    "# show query image\n",
    "render_images([{\"doc\":{\"image_name\": q_im_file}}])\n",
    "# do search\n",
    "render_images(search_by_image(q_im_file, im_width, im_height, module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image to image search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_im_file = '14526359.jpg'\n",
    "\n",
    "# show query image\n",
    "render_images([{\"doc\":{\"image_name\": q_im_file}}])\n",
    "# do search\n",
    "render_images(search_by_image(q_im_file, im_width, im_height, module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image to image search 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_im_file = '21164875.jpg'\n",
    "\n",
    "# show query image\n",
    "render_images([{\"doc\":{\"image_name\": q_im_file}}])\n",
    "# do search\n",
    "render_images(search_by_image(q_im_file, im_width, im_height, module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image to image search 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "https://user-images.githubusercontent.com/19545678/62864838-6b6b9700-bd2a-11e9-8acb-534a0728d0ff.png",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_im_file = '23008340.jpg'\n",
    "\n",
    "# show query image\n",
    "render_images([{\"doc\":{\"image_name\": q_im_file}}])\n",
    "# do search\n",
    "render_images(search_by_image(q_im_file, im_width, im_height, module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for this tutorial. Thanks, happy hacking..!\n",
    "\n",
    "created with ❤️ a-mma.indic (a_മ്മ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
